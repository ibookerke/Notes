A type of [[Gradient descent]] where we are supposed to:
- Pick a random data point
- Evaluate (a very noisy) gradient at this data point

### Features:
- Works online (on streams of data, rather than fixed data sets)
- Easy to implement
- Efficient in terms of computations and memory requirements(Especially on large scale data sets)
- Easy to parallelize
- very popular in machine Learning

Also called online gradient descent

Much more popular in comparison with [[Batch Gradient Descent]]
