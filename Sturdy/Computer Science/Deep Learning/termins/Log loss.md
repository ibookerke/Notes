Cross-entropy loss, or log loss,Â **measures the performance of a classification model whose output is a probability value between 0 and 1**.

Objective:
Calculate loss of the model with probability values, i.e., one-hot encoded label and Softmax outputs.

Binary Classification:
![[Screen Shot 2023-09-27 at 08.57.16.png]]
Multiclass Classification:
![[Screen Shot 2023-09-27 at 08.57.31.png]]

![[Screen Shot 2023-09-27 at 08.58.15.png]]
